[{"title":"一：线性回归","url":"/2020/07/21/机器学习笔记一：线性回归/","content":"\n# 一 . 概述\n在统计学中，线性回归是利用线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系的一种分析。\n\n一个自变量称为一元回归。\n\n多个自变量称为多元回归。\n\n# 二 . 所属分类\n\n线性回归一般属于 监督学习。\n  \n# 三 . 数学相关\n\n  一般用梯度下降的方法来拟合线性回归的线，让其尽量的均匀分割散列点。\n\n  其中以下是常用的损失函数，用于计算最小化损失。\n\n  1. Mean Absolute Error (平均绝对误差)\n\n  2. Mean Squared Error (均方误差)\n\n# 四 . 线性回归示例代码\n\n","tags":["机器学习笔记"]},{"title":"使用 Rust WebAssembly 0拷贝进行计算加速","url":"/2020/06/26/使用RustWebAssembly0拷贝进行计算加速/","content":"\ndemo: https://github.com/aircloud/rust-wasm-demo  \n\n其他资料：[入门 Rust 开发 WebAssembly](https://zhuanlan.zhihu.com/p/104299612)\n\n一般来说，使用 WebAssembly 能够在一定程度上提高性能，不过有的时候我们也许会发现，使用 WebAssembly 之后，有的时候我们不仅发现性能没有提升，反而下降了许多甚至数倍，实际上这是因为，使用 WebAssembly 需要非常谨慎，有很多细节都会大幅度影响性能，比如：\n\n* 我们编译采用的是 debug 还是 release 方式。\n* 最后编译的结果是否采用了不同级别的优化，如果使用了 `opt-level = 's'` 那么通常速度也会下降很多。\n* 是否在 JS 和 rust 之间存在大量的数据拷贝，因为很多代码是工具链生成的，也许有的时候我们会忽视这一点。\n\n本文针对以上等一些问题特别是第三点，给出一个 wasm 优化的参考方案，并给出示例代码。\n\n### 编译优化\n\n我们在优化数据拷贝之前，对于编译我们可以做一些前置的简单的工作。\n\n* 检查 Cargo.toml 脚本中 `[profile.release]` 中的 `opt-level` 选项，确认我们所使用的值：\n\n```\nThis flag controls the optimization level.\n\n0: no optimizations, also turns on cfg(debug_assertions) (the default).\n1: basic optimizations.\n2: some optimizations.\n3: all optimizations.\ns: optimize for binary size.\nz: optimize for binary size, but also turn off loop vectorization.\nNote: The -O flag is an alias for -C opt-level=2.\n\nThe default is 0.\n```\n\n如果我们使用了 ‘s’ 或者 'z'，那么通常会牺牲一部分性能（对于 demo 而言，使用 'z'， wasm 的性能也只有 js 的 20%），因为其主要是对体积进行一定的优化，所以如果优化前的体积我们可以接受的话，通常不需要这样的优化。\n\n在以上的前提下，我们使用 `--release` 的方式编译，通常就可以了。\n\n### 减少拷贝\n\n在这之前，我们需要有一个认知：\n\n**通过 rust 工具链编译的 wasm 代码，所有参数传入都是需要拷贝一次的，包括我们传入 ArrayBuffer 等 Buffer 类型的参数。**这是由于 wasm 只能访问自己的线性内存，而这个拷贝，通常是我们在处理大规模计算的一个坎，有的时候虽然 wasm 计算快一点，但是拷贝的消耗还是比较大的，加之 js 有若干 v8 优化的加持，可能和 wasm 也相差不多。\n\n所以我们要把计算移植到 wasm 中的话，首先要解决的就是大规模数据拷贝的问题。\n\n这里的一般思路为：\n\n1. wasm 分配内存：调用 wasm 的方法，在 wasm 内存中分配空间，返回指针位置\n2. js 写入数据：js 端在 wasm 的 memory arraybuffer 上，按指针位置和数据量建立 view，把数据写入\n3. wasm 计算：调用 wasm 方法完成计算， 返回计算好的批量结果的指针位置和大小\n4. js 读取数据：js 端在 wasm 的 memory arraybuffer上，按指针位置和数据量建立 view，把数据读出\n\n接下来，我们通过一个 demo 来完成以上几点，demo 的主要功能为：\n\n* 初始化一个 ImageData，内容随机。\n* 分别使用 js 和 WebAssembly 进行高斯模糊计算，并计算二者的时间，进行对比。\n\n这里的 demo 只是辅助进行验证改方案的可行性并且给出一个示例，并不作为一个标准的 benchmark 去对比 js 和 WebAssembly 的性能，同时，也并没有 UI 展示，计算结果输出在控制台中。\n\n最终笔者运行的结果为，js 比 WebAssembly 慢 30% 左右。\n\n#### 1. wasm 分配内存\n\n这部分的通用做法，即我们在 wasm 的 rust 中分配一个数组（Vec），然后把其指针传递给 js：\n\n```\n// rust：\n#[wasm_bindgen]\npub fn new_buffer(key: String, len: usize) -> *const u8 {\n  // GlobalBufferStorage 是一个 lazy_static\n  let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap();\n  let mut buffer = vec![255; len];\n  let ptr = buffer.as_ptr();\n  global_buffer_storage.buffer_map.insert(key, buffer);\n  ptr\n}\n```\n\n为了后续方便寻找到这段数据，我们可以使用一个 key 将这个 Vec 联系起来，并且在 Rust 中放入全局（可以使用 lazy_static!，因为这种类型的数据没有办法直接定义在全局），之后通过 key 来查找数据。\n\n在 js 中，我们就可以建立各种 TypedArray 对其进行操作：\n\n```\nconst ptr = this.wasm!.new_buffer(key, len);\nconst u8Arr = new Uint8ClampedArray(this.wasm!.get_wasm_buffer(), ptr, len);\n```\n\n**这个时候，我们在 js 或 rust 任何一侧改了这个数据之后，都可以在另外一侧访问到。**\n\n实际上，在 js 侧的比如 [ImageData](https://developer.mozilla.org/en-US/docs/Web/API/ImageData/ImageData) 等一些对象中，也支持我们传递一个 TypedArray 进行初始化，这让我们在比如 canvas 等应用场景下，使用 wasm 分配的内存更为方便。\n\n```\nconst imageData = new ImageData(u8Arr, width, height);\n```\n\n#### 2. js 写入数据\n\n如果我们需要在 js 侧写入数据，实际上这个时候我们得到的 TypedArray 已经和直接使用 js new 的 TypedArray 在使用上没有差别，可以正常按照数组的方式进行数据写入。\n\n不过，这里需要注意的是，js 写入通过 wasm 分配内存建立的 TypedArray，有些场景下在一定程度上速度要慢于直接使用 js new 的 TypedArray（不过在笔者的测试数据中，wasm 分配的方式反而是更快的），所以如果我们是一个高频的数据写入的场景，比如帧数据等，这个时候最好进行一次对比测试。\n\n\n#### 3. wasm 计算\n\n当我们真正需要进行计算的时候，我们可以调用 wasm 的计算函数，并且传入上文中定义的 key，这样 wasm 的 rust 函数可以直接找到这段数据，这里我们的 demo 为一段计算卷积的函数：\n\n```\n#[wasm_bindgen]\npub fn convolution(key: String, width: usize, height: usize, kernel: Vec<i32>) {\n  let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap();\n  let kernel_length = kernel.iter().sum::<i32>() as i32;\n  if let Some(buffer) = global_buffer_storage.buffer_map.get_mut(&key) {\n    for i in 1..width-1 {\n      for j in 1..height-1 {\n        let mut newR: i32 = 0;\n        let mut newG: i32 = 0;\n        let mut newB: i32 = 0;\n        for x in 0..3 { // 取前后左右共9个格子\n          for y in 0..3 {\n            newR += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 0] as i32 * kernel[y * 3 + x] / kernel_length;\n            newG += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 1] as i32 * kernel[y * 3 + x] / kernel_length;\n            newB += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 2] as i32 * kernel[y * 3 + x] / kernel_length;\n          }\n        }\n        buffer[width * j * 4 + i * 4 + 0] = newR as u8;\n        buffer[width * j * 4 + i * 4 + 1] = newG as u8;\n        buffer[width * j * 4 + i * 4 + 2] = newB as u8;\n      }\n    }\n  } else {\n    return ();\n  }\n}\n```\n\n因为这段函数对应操作的内存数据实际上已经在 wasm 和 js 之间共享了，所以也是不需要返回值的，等计算完成后 js 直接去读之前建立的 TypedArray，甚至直接使用通过 TypedArray 创建的 ImageData，进行绘制上屏等后续操作。\n\n#### 4. js 读取数据\n\n在 demo 中，我们可以直接通过 `CanvasRenderingContext2D.putImageData()` 传入之前获取的 imageData，绘制上屏。\n\n### 其他方案\n\n实际上，我们如果目的是加速 js 计算，不仅仅有 WebAssembly 这一个方案可以选择，如果我们的环境中拥有可以访问 Node 的能力或者可以访问原生模块的能力（比如，我们的应用运行在 electron 环境，或者是一些移动客户端），也可以采用比如 addon 的方式来运行我们的计算部分，相比于 wasm，这部分的优缺点在于：\n\n优点：\n\n* 通常可以更好的控制优化，甚至做到汇编级别的优化定制，性能提升空间更高（同样也可能会面临数据拷贝的问题，也需要一定方式减少拷贝）。\n* 在重 addon 的环境下（例如，其他大量功能也依赖 addon），可以更好的处理函数调用关系、依赖库使用等，一定程度上减少体积和增加开发的便捷性，而 wasm 会被编译成一个独立的二进制文件，处于沙盒环境中，无法直接调用其他的动态库。\n\n缺点：\n\n* 无法做到像 wasm 一样跨平台，并且可以同时运行在网页、桌面环境、移动端等任何 Webview 存在的环境中。\n\n不过总之，如果使用得当，二者的性能都是可以优于原生的 js，都可以作为优化方案考虑。\n","tags":["rust"]},{"title":"CentOS7下安装和配置redis","url":"/2016/10/04/CentOS7下安装和配置redis/","content":"\nSimple inline $$ a = b + c $$ .\n\n$$\\frac{\\partial u}{\\partial t}\n= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\n\\frac{\\partial^2 u}{\\partial y^2} +\n\\frac{\\partial^2 u}{\\partial z^2}\\right)$$\n\n\nRedis是一个高性能的，开源key-value型数据库。是构建高性能，可扩展的Web应用的完美解决方案，可以内存存储亦可持久化存储。因为要使用跨进程，跨服务级别的数据缓存，在对比多个方案后，决定使用Redis。顺便整理下Redis的安装过程，以便查阅。\n\n\n 1 . 下载Redis\n目前，最新的Redist版本为3.0，使用wget下载，命令如下：\n```\n\n# wget http://download.redis.io/releases/redis-3.0.4.tar.gz\n\n```\n 2 . 解压Redis\n下载完成后，使用tar命令解压下载文件：\n```\n\n# tar -xzvf redis-3.0.4.tar.gz\n```\n3 . 编译安装Redis\n切换至程序目录，并执行make命令编译：\n```\n# cd redis-3.0.4\n# make\n```\n执行安装命令\n```\n# make install\n```\nmake install安装完成后，会在/usr/local/bin目录下生成下面几个可执行文件，它们的作用分别是：\n\n* redis-server：Redis服务器端启动程序\n* redis-cli：Redis客户端操作工具。也可以用telnet根据其纯文本协议来操作\n* redis-benchmark：Redis性能测试工具\n* redis-check-aof：数据修复工具\n* redis-check-dump：检查导出工具\n\n备注\n\n有的机器会出现类似以下错误：\n```\nmake[1]: Entering directory `/root/redis/src'\nYou need tcl 8.5 or newer in order to run the Redis test\n……\n```\n这是因为没有安装tcl导致，yum安装即可：\n```\nyum install tcl\n```\n4 . 配置Redis\n复制配置文件到/etc/目录：\n```\n# cp redis.conf /etc/\n```\n为了让Redis后台运行，一般还需要修改redis.conf文件：\n```\nvi /etc/redis.conf\n```\n修改daemonize配置项为yes，使Redis进程在后台运行：\n```\ndaemonize yes\n```\n5 . 启动Redis\n配置完成后，启动Redis：\n```\n# cd /usr/local/bin\n# ./redis-server /etc/redis.conf\n```\n检查启动情况：\n```\n# ps -ef | grep redis\n```\n看到类似下面的一行，表示启动成功：\n```\nroot     18443     1  0 13:05 ?        00:00:00 ./redis-server *:6379 \n```\n6 . 添加开机启动项\n让Redis开机运行可以将其添加到rc.local文件，也可将添加为系统服务service。本文使用rc.local的方式，添加service请参考：Redis 配置为 Service 系统服务 。\n\n为了能让Redis在服务器重启后自动启动，需要将启动命令写入开机启动项：\n```\necho \"/usr/local/bin/redis-server /etc/redis.conf\" >>/etc/rc.local\n```\n7 . Redis配置参数\n在 前面的操作中，我们用到了使Redis进程在后台运行的参数，下面介绍其它一些常用的Redis启动参数：\n```\ndaemonize：是否以后台daemon方式运行\npidfile：pid文件位置\nport：监听的端口号\ntimeout：请求超时时间\nloglevel：log信息级别\nlogfile：log文件位置\ndatabases：开启数据库的数量\nsave * *：保存快照的频率，第一个*表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。\nrdbcompression：是否使用压缩\ndbfilename：数据快照文件名（只是文件名）\ndir：数据快照的保存目录（仅目录）\nappendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。\nappendfsync：appendonlylog如何同步到磁盘。三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步\n```\n","tags":["redis"]}]